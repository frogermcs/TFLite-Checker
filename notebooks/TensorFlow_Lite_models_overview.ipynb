{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TensorFlow Lite models overview.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4YCNkzWlj6eH","colab_type":"text"},"source":["# TensorFlow Lite models overview"]},{"cell_type":"markdown","metadata":{"id":"9qUjEin5jZIu","colab_type":"text"},"source":["This notebook shows some basic information about two TensorFlow Lite models. For more details, take a look at blog post describing how to learn about models configuration before implementing them in mobile application.\n","\n","[Inspecting TensorFlow Lite image classification model](https://thinkmobile.dev/inspecting-tensorflow-lite-image-classification-model/)"]},{"cell_type":"markdown","metadata":{"id":"kJLoEm7akH9b","colab_type":"text"},"source":["## TensorFlow 2.0 alpha and Colaboratory\n","Examples presented in this notebook are built on top of TensorFlow 2.0 alpha version. As long as it's not a stable version yet, there is no guarantee that anything here will work as it should. \n","\n","This notebook was created only for the Colaboratory environment. It requires some changes to make it working on Docker environment described in linked blog post."]},{"cell_type":"code","metadata":{"id":"K7yq78-M9mzS","colab_type":"code","outputId":"81a0bf32-2c96-41d6-916d-1cb974906d52","executionInfo":{"status":"ok","timestamp":1558453877770,"user_tz":-120,"elapsed":79227,"user":{"displayName":"Mirosław Stanek","photoUrl":"https://lh6.googleusercontent.com/-PV8uxoRZdpU/AAAAAAAAAAI/AAAAAAAA4BI/VQgFGUBLzxM/s64/photo.jpg","userId":"13813797782320875257"}},"colab":{"base_uri":"https://localhost:8080/","height":540}},"source":["# Install TensorFlow 2.0 alpha\n","!pip install -U tensorflow-gpu==2.0.0-alpha0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting tensorflow-gpu==2.0.0-alpha0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/66/32cffad095253219d53f6b6c2a436637bbe45ac4e7be0244557210dc3918/tensorflow_gpu-2.0.0a0-cp36-cp36m-manylinux1_x86_64.whl (332.1MB)\n","\u001b[K     |████████████████████████████████| 332.1MB 42kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.33.4)\n","Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.15.0)\n","Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (3.7.1)\n","Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.1.0)\n","Collecting tf-estimator-nightly<1.14.0.dev2019030116,>=1.14.0.dev2019030115 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/82/f16063b4eed210dc2ab057930ac1da4fbe1e91b7b051a6c8370b401e6ae7/tf_estimator_nightly-1.14.0.dev2019030115-py2.py3-none-any.whl (411kB)\n","\u001b[K     |████████████████████████████████| 419kB 41.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.16.3)\n","Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.2.2)\n","Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.12.0)\n","Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (0.7.1)\n","Collecting google-pasta>=0.1.2 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/68/a14620bfb042691f532dcde8576ff82ee82e4c003cdc0a3dbee5f289cee6/google_pasta-0.1.6-py3-none-any.whl (51kB)\n","\u001b[K     |████████████████████████████████| 61kB 27.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.9)\n","Collecting tb-nightly<1.14.0a20190302,>=1.14.0a20190301 (from tensorflow-gpu==2.0.0-alpha0)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/51/aa1d756644bf4624c03844115e4ac4058eff77acd786b26315f051a4b195/tb_nightly-1.14.0a20190301-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 37.5MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-alpha0) (1.0.7)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-alpha0) (41.0.1)\n","Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (3.1)\n","Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190302,>=1.14.0a20190301->tensorflow-gpu==2.0.0-alpha0) (0.15.4)\n","Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0.0-alpha0) (2.8.0)\n","Installing collected packages: tf-estimator-nightly, google-pasta, tb-nightly, tensorflow-gpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I5c7T0x59r3C","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hbpyHiEZ9psq","colab_type":"code","colab":{}},"source":["print(\"TensorFlow Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Is GPU available: \", tf.test.is_gpu_available())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e8NdAIs0Ms-B","colab_type":"text"},"source":["Download and unpack models:\n","\n","\n","*   Mnist model created as a part of blog post [TensorFlow Lite classification on Android ](https://thinkmobile.dev/mobile-intelligence-tensorflow-lite-classification-on-android/)\n","*   MobileNet v2 model taken from TensorFlow [hosted models website](https://www.tensorflow.org/lite/guide/hosted_models).\n","\n"]},{"cell_type":"code","metadata":{"id":"S8IZFSij9L46","colab_type":"code","colab":{}},"source":["!curl -LO https://www.dropbox.com/s/4l8v42ofze3s6e2/mnist_model.tflite\n","!curl -LO http://download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224.tgz\n","  \n","!mkdir mobilenet_v2_float\n","!tar -xzvf mobilenet_v2_1.0_224.tgz -C mobilenet_v2_float"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnID21srR5t7","colab_type":"text"},"source":["# MNIST model info\n","\n","Let's collect some information about Mnist TF Lite model."]},{"cell_type":"code","metadata":{"id":"MBTdiJ2S6U-q","colab_type":"code","colab":{}},"source":["TFLITE_MNIST_MODEL = \"mnist_model.tflite\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WXbvcMhN9Z1V","colab_type":"code","colab":{}},"source":["interpreter = tf.lite.Interpreter(model_path=TFLITE_MNIST_MODEL)\n","interpreter.allocate_tensors()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dJgb2Tun-oXp","colab_type":"code","colab":{}},"source":["print(\"== Input details ==\")\n","print(\"name:\", interpreter.get_input_details()[0]['name'])\n","print(\"shape:\", interpreter.get_input_details()[0]['shape'])\n","print(\"type:\", interpreter.get_input_details()[0]['dtype'])\n","\n","print(\"\\nDUMP INPUT\")\n","print(interpreter.get_input_details()[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcIY44S5-tLg","colab_type":"code","colab":{}},"source":["print(\"\\n== Output details ==\")\n","print(\"name:\", interpreter.get_output_details()[0]['name'])\n","print(\"shape:\", interpreter.get_output_details()[0]['shape'])\n","print(\"type:\", interpreter.get_output_details()[0]['dtype'])\n","\n","print(\"\\nDUMP OUTPUT\")\n","print(interpreter.get_output_details()[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-oj7hpT0R9C8","colab_type":"text"},"source":["# MobileNet v2 model info\n","\n","Now let's collect some information about MobileNet v2 TF Lite model."]},{"cell_type":"code","metadata":{"id":"RDtlM_zy9vKI","colab_type":"code","colab":{}},"source":["MOBILENET_V2_FLOAT_MODEL = \"mobilenet_v2_float/mobilenet_v2_1.0_224.tflite\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LppI8hV7SYxK","colab_type":"code","colab":{}},"source":["mobilenetV2F_interpreter = tf.lite.Interpreter(model_path=MOBILENET_V2_FLOAT_MODEL)\n","mobilenetV2F_interpreter.allocate_tensors()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2aQigo4oSeXE","colab_type":"code","colab":{}},"source":["print(\"== Input details ==\")\n","print(\"name:\", mobilenetV2F_interpreter.get_input_details()[0]['name'])\n","print(\"shape:\", mobilenetV2F_interpreter.get_input_details()[0]['shape'])\n","print(\"type:\", mobilenetV2F_interpreter.get_input_details()[0]['dtype'])\n","\n","print(\"\\nDUMP INPUT\")\n","print(mobilenetV2F_interpreter.get_input_details()[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yAmUML7YSjL8","colab_type":"code","colab":{}},"source":["print(\"\\n== Output details ==\")\n","print(\"name:\", mobilenetV2F_interpreter.get_output_details()[0]['name'])\n","print(\"shape:\", mobilenetV2F_interpreter.get_output_details()[0]['shape'])\n","print(\"type:\", mobilenetV2F_interpreter.get_output_details()[0]['dtype'])\n","\n","print(\"\\nDUMP OUTPUT\")\n","print(mobilenetV2F_interpreter.get_output_details()[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7C8IMh2JMfiL","colab_type":"text"},"source":["## MobileNet model check\n","\n","Run inference process on MobileNet model with image input data normalized to two different ranges: [-1, 1] and [0, 1]."]},{"cell_type":"code","metadata":{"id":"fpld3UQLSvWA","colab_type":"code","colab":{}},"source":["from PIL import Image\n","import PIL.ImageOps  \n","import requests\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","imgUrl = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Compaqarmada7800.jpg/1024px-Compaqarmada7800.jpg\"\n","img = Image.open(requests.get(imgUrl, stream=True).raw)\n","img.load()\n","img = img.resize((224, 224), PIL.Image.ANTIALIAS)\n","\n","plt.grid(False)\n","plt.xticks([])\n","plt.yticks([])\n","plt.imshow(img)\n","\n","# Normalize to [0, 1]\n","data = np.asarray( img, dtype=\"int32\" ) / 255.0\n","\n","# Normalize to [-1, 1]\n","data2 = (np.asarray( img, dtype=\"int32\" ) - 128.0) / 128.0\n","\n","# Inference on input data normalized to [0, 1]\n","inputImg = np.expand_dims(data,0).astype(np.float32)\n","input_details = mobilenetV2F_interpreter.get_input_details()\n","mobilenetV2F_interpreter.set_tensor(input_details[0]['index'], inputImg)\n","\n","mobilenetV2F_interpreter.invoke()\n","\n","output_details = mobilenetV2F_interpreter.get_output_details()\n","output_data = mobilenetV2F_interpreter.get_tensor(output_details[0]['index'])\n","print(\"Predicted value for [0, 1] normalization. Label index: {}, confidence: {:2.0f}%\"\n","      .format(np.argmax(output_data), \n","              100 * output_data[0][np.argmax(output_data)]))\n","\n","# Inference on input data normalized to [-1, 1]\n","inputImg2 = np.expand_dims(data2,0).astype(np.float32)\n","input_details = mobilenetV2F_interpreter.get_input_details()\n","mobilenetV2F_interpreter.set_tensor(input_details[0]['index'], inputImg2)\n","\n","mobilenetV2F_interpreter.invoke()\n","\n","output_details = mobilenetV2F_interpreter.get_output_details()\n","output_data = mobilenetV2F_interpreter.get_tensor(output_details[0]['index'])\n","print(\"Predicted value for [-1, 1] normalization. Label index: {}, confidence: {:2.0f}%\".format(np.argmax(output_data), 100 * output_data[0][np.argmax(output_data)]))"],"execution_count":0,"outputs":[]}]}